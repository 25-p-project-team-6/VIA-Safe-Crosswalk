{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90fbdb8",
   "metadata": {},
   "source": [
    "# YOLOv11n Video Inference (Full Features + Color Correction)\n",
    "\n",
    "**Features:**\n",
    "- **Batch Processing**: Runs on all videos in input folder.\n",
    "- **Frame Saving**: Saves `all_frames` and `detected_frames`.\n",
    "- **Strict NMS**: `agnostic_nms=True`, `iou=0.05` (Ultra Strict).\n",
    "- **Color Correction**: \n",
    "    - If YOLO detects **Green**, but pixel analysis shows **< 5% Green** and **> 5% Red**, it swaps to **Red** (and vice versa).\n",
    "\n",
    "**Label Format**: `Class Conf | ColorRatio`\n",
    "**Model**: `yolo11n_mixed/run_9cls_final/weights/best.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d26f498e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: weights/best_float16_448.tflite\n",
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "input_video_dir = \"/home/prml/StudentsWork/SeokJin/Pprojects/test_video\"\n",
    "output_base_dir = \"inference_results_finetune_final_448_half\"\n",
    "model_path = \"weights/best_float16_448.tflite\"\n",
    "\n",
    "# Settings\n",
    "CONF_THRES = 0.298  # Increased from 0.15 to reduce noise\n",
    "IOU_THRES = 0.05   # Decreased from 0.3 to 0.05 (Ultra Strict NMS to remove nested boxes)\n",
    "IMGSZ = 448      # Inference image size (matches TFLite)\n",
    "DEVICE = 0       # GPU Device ID\n",
    "\n",
    "COLORS = {\n",
    "    6: (0, 255, 0),    # Green\n",
    "    7: (0, 0, 255),    # Red\n",
    "}\n",
    "DEFAULT_COLOR = (255, 200, 0)\n",
    "\n",
    "# Load Model\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Loading model: {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "else:\n",
    "    print(\"Model not found! Please check the path.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74a68dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 videos.\n",
      "\n",
      "Processing: 20251209_221018.mp4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765522184.166333  524388 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765522184.172460  524388 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1765522184.188396  524388 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765522184.188419  524388 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765522184.188421  524388 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765522184.188423  524388 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights/best_float16_448.tflite for TensorFlow Lite inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prml/miniconda3/envs/rfdetr/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Frame 5300...\n",
      "Saved: 20251209_221018 (Detected: 4784/5311)\n",
      "\n",
      "Processing: 20251209_220841.mp4...\n",
      "  Frame 300...\n",
      "Saved: 20251209_220841 (Detected: 194/343)\n",
      "\n",
      "Processing: 20251209_220956.mp4...\n",
      "  Frame 550...\n",
      "Saved: 20251209_220956 (Detected: 341/568)\n",
      "\n",
      "Processing: 20251209_220543.mp4...\n",
      "  Frame 1950...\n",
      "Saved: 20251209_220543 (Detected: 1632/1974)\n",
      "\n",
      "Processing: 20251209_220653.mp4...\n",
      "  Frame 3000...\n",
      "Saved: 20251209_220653 (Detected: 2029/3028)\n",
      "\n",
      "Processing: 20251209_221649.mp4...\n",
      "  Frame 5200...\n",
      "Saved: 20251209_221649 (Detected: 4529/5205)\n"
     ]
    }
   ],
   "source": [
    "def calculate_color_ratio(roi, cls_id):\n",
    "    \"\"\"\n",
    "    Calculates the ratio of specific color pixels in the ROI.\n",
    "    7 (Green) -> Green pixels\n",
    "    8 (Red) -> Red pixels\n",
    "    \"\"\"\n",
    "    if roi.size == 0: return 0.0\n",
    "    \n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    if cls_id == 6: # Green (Wide Range)\n",
    "        lower = np.array([25, 25, 40])\n",
    "        upper = np.array([100, 255, 255])\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "        \n",
    "    elif cls_id == 7: # Red\n",
    "        lower1 = np.array([0, 50, 50])\n",
    "        upper1 = np.array([10, 255, 255])\n",
    "        lower2 = np.array([170, 50, 50])\n",
    "        upper2 = np.array([180, 255, 255])\n",
    "        mask = cv2.bitwise_or(\n",
    "            cv2.inRange(hsv, lower1, upper1),\n",
    "            cv2.inRange(hsv, lower2, upper2)\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        return 0.0\n",
    "        \n",
    "    ratio = cv2.countNonZero(mask) / (roi.shape[0] * roi.shape[1])\n",
    "    return ratio\n",
    "\n",
    "def process_video_batch():\n",
    "    if not model or not os.path.exists(input_video_dir):\n",
    "        return\n",
    "\n",
    "    video_files = [f for f in os.listdir(input_video_dir) if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "    print(f\"Found {len(video_files)} videos.\")\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(input_video_dir, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        print(f\"\\nProcessing: {video_file}...\")\n",
    "        \n",
    "        # Setup Output\n",
    "        save_dir = os.path.join(output_base_dir, video_name)\n",
    "        all_frames_dir = os.path.join(save_dir, \"all_frames\")\n",
    "        detected_frames_dir = os.path.join(save_dir, \"detected_frames\")\n",
    "        \n",
    "        if os.path.exists(save_dir): shutil.rmtree(save_dir)\n",
    "        os.makedirs(all_frames_dir, exist_ok=True)\n",
    "        os.makedirs(detected_frames_dir, exist_ok=True)\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        out = cv2.VideoWriter(\n",
    "            os.path.join(save_dir, f\"{video_name}_result.mp4\"),\n",
    "            cv2.VideoWriter_fourcc(*'avc1'), fps, (w, h)\n",
    "        )\n",
    "        \n",
    "        results = model.predict(\n",
    "            source=video_path, stream=True, \n",
    "            conf=CONF_THRES, iou=IOU_THRES, agnostic_nms=True, verbose=False, imgsz=IMGSZ, device=DEVICE\n",
    "        )\n",
    "        \n",
    "        frame_cnt = 0\n",
    "        detected_cnt = 0\n",
    "        \n",
    "        for r in results:\n",
    "            frame = r.orig_img.copy()\n",
    "            has_detection = False\n",
    "            \n",
    "            if len(r.boxes) > 0:\n",
    "                has_detection = True\n",
    "                for box in r.boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                    cls_id = int(box.cls[0].item())\n",
    "                    conf = box.conf[0].item()\n",
    "                    \n",
    "                    # Color Correction Logic\n",
    "                    color_ratio = 0.0\n",
    "                    if cls_id in [6, 7]:\n",
    "                        roi = frame[y1:y2, x1:x2]\n",
    "                        color_ratio = calculate_color_ratio(roi, cls_id)\n",
    "                        \n",
    "                        # Correct Weak Detections (Ratio <= 0.05)\n",
    "                        if color_ratio <= 0.05:\n",
    "                            other_cls_id = 7 if cls_id == 6 else 6\n",
    "                            other_ratio = calculate_color_ratio(roi, other_cls_id)\n",
    "                            \n",
    "                            # Only swap if opposite color is CLEARLY present\n",
    "                            if other_ratio > 0.05:\n",
    "                                cls_id = other_cls_id\n",
    "                                color_ratio = other_ratio\n",
    "                                # Note: conf remains same (model confidence)\n",
    "\n",
    "                    cls_name = model.names[cls_id]\n",
    "\n",
    "                    # Draw\n",
    "                    color = COLORS.get(cls_id, DEFAULT_COLOR)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
    "                    \n",
    "                    label = f\"{cls_name} {conf:.2f}\"\n",
    "                    if cls_id in [6, 7]:\n",
    "                        label += f\" | P: {color_ratio:.2f}\"\n",
    "                        \n",
    "                    (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "                    cv2.rectangle(frame, (x1, y1 - 20), (x1 + tw, y1), color, -1)\n",
    "                    cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "            \n",
    "            out.write(frame)\n",
    "            \n",
    "            # Frame Saving\n",
    "            fname = f\"frame_{frame_cnt:05d}.jpg\"\n",
    "            cv2.imwrite(os.path.join(all_frames_dir, fname), frame)\n",
    "            if has_detection:\n",
    "                cv2.imwrite(os.path.join(detected_frames_dir, fname), frame)\n",
    "                detected_cnt += 1\n",
    "            \n",
    "            frame_cnt += 1\n",
    "            if frame_cnt % 50 == 0:\n",
    "                print(f\"  Frame {frame_cnt}...\", end='\\r')\n",
    "                \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(f\"\\nSaved: {video_name} (Detected: {detected_cnt}/{frame_cnt})\")\n",
    "\n",
    "process_video_batch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rfdetr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
